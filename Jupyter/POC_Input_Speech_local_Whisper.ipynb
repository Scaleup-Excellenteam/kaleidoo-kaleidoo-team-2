{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-16T12:27:16.580506Z",
     "start_time": "2024-09-16T12:27:16.570337Z"
    }
   },
   "source": [
    "import torch\n",
    "import librosa\n",
    "from transformers import pipeline\n",
    "import time"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Check model without telling her language of audio\n",
    " As audio example we use 50 seconds dialog in Hebrew with medium quality sound."
   ],
   "id": "6e1c767e84a37a21"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T12:21:29.092514Z",
     "start_time": "2024-09-16T12:17:53.237752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Track the total time for each part\n",
    "start_time = time.time()\n",
    "\n",
    "# Set device to CUDA if available\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Measure pipeline initialization time\n",
    "init_pipe_start = time.time()\n",
    "# Initialize the pipeline for automatic speech recognition\n",
    "pipe = pipeline(\n",
    "  \"automatic-speech-recognition\",\n",
    "  model=\"ivrit-ai/whisper-large-v2-tuned\",\n",
    "  chunk_length_s=30,\n",
    "  device=device,\n",
    ")\n",
    "init_pipe_end = time.time()\n",
    "\n",
    "# Load audio file\n",
    "load_audio_start = time.time()\n",
    "audio_file_path = \"POC_Examples/audio_sample_1.mp3\"\n",
    "audio_array, sampling_rate = librosa.load(audio_file_path, sr=16000)\n",
    "load_audio_end = time.time()\n",
    "\n",
    "# Create a dictionary similar to what the pipeline expects\n",
    "create_sample_start = time.time()\n",
    "sample = {\n",
    "    \"array\": audio_array,\n",
    "    \"sampling_rate\": sampling_rate\n",
    "}\n",
    "create_sample_end = time.time()\n",
    "\n",
    "# Get text prediction with timestamps from the audio file\n",
    "prediction_start = time.time()\n",
    "prediction = pipe(sample, batch_size=8, return_timestamps=True)[\"chunks\"]\n",
    "prediction_end = time.time()\n",
    "\n",
    "# Print each chunk and the time range\n",
    "print_chunks_start = time.time()\n",
    "for chunk in prediction:\n",
    "    start, end = chunk['timestamp']  # timestamp is a tuple (start, end)\n",
    "    text = chunk['text']\n",
    "    print(f\"Text: {text}, Start: {start:.2f}, End: {end:.2f}\")\n",
    "print_chunks_end = time.time()\n",
    "\n",
    "# Calculate total times\n",
    "total_time = time.time() - start_time\n",
    "pipe_time = init_pipe_end - init_pipe_start\n",
    "load_audio_time = load_audio_end - load_audio_start\n",
    "create_sample_time = create_sample_end - create_sample_start\n",
    "prediction_time = prediction_end - prediction_start\n",
    "print_chunks_time = print_chunks_end - print_chunks_start\n",
    "\n",
    "# Print timing results\n",
    "print(f\"Total time: {total_time:.2f} seconds\")\n",
    "print(f\"Pipeline initialization time: {pipe_time:.2f} seconds\")\n",
    "print(f\"Audio loading time: {load_audio_time:.2f} seconds\")\n",
    "print(f\"Sample creation time: {create_sample_time:.2f} seconds\")\n",
    "print(f\"Prediction time: {prediction_time:.2f} seconds\")\n",
    "print(f\"Chunk printing time: {print_chunks_time:.2f} seconds\")\n"
   ],
   "id": "117fc10cae75fc9d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "618913b89dcb4c0fa5e1856ae69c90b8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: רובן, תחרות אכילת לפות, אתה נגד ערן לוי, מי לוקח?, Start: 0.00, End: 6.00\n",
      "Text:  אה, חוזרים שתרענו אותי על כדורגל, אתם מדברים איתי על לפות עכשיו. דווקא במקרה הזה אני לא אוהב לפות, אבל אם מצא, אז כבר שיהנו. אבל אני לא, עדיף שאני לא נהיה לשאלה הזאת, אמרתי לכם, דברו איתי על כדורגל, לא מעבר לזה., Start: 6.00, End: 18.00\n",
      "Text:  אוקיי, שאלה לגבי כדורגל, למה לכדורגלנים אומרים שאין ידע כללי?, Start: 18.00, End: 23.00\n",
      "Text:  לא יודע, אולי זה סטיגמה, שחושבים שהם אולי טיפשים או משהו כזה? אמרתי לך, זה... Why do people say that there is no general knowledge about football? I don't know, maybe it's a stigma that people think that they are maybe stupid or something like that?, Start: 23.00, End: 28.00\n",
      "Text:  I told you, it's..., Start: 28.00, End: 29.00\n",
      "Text:  How's your general knowledge?, Start: 29.00, End: 30.00\n",
      "Text:  It's okay., Start: 30.00, End: 31.00\n",
      "Text:  Let's say, what was the profession of Yohanan Asandlar?, Start: 31.00, End: 34.00\n",
      "Text:  No, I was talking about something in sports., Start: 34.00, End: 37.00\n",
      "Text:  Thank you, Reuben., Start: 37.00, End: 38.00\n",
      "Text:  Great idea., Start: 38.00, End: 39.00\n",
      "Text:  Yeah, it was a short and..., Start: 39.00, End: 40.00\n",
      "Text:  See you at the wedding., Start: 40.00, End: 41.00\n",
      "Text:  Yeah., Start: 41.00, End: 42.00\n",
      "Text:  What wedding?, Start: 42.00, End: 43.00\n",
      "Text:  Oh, sorry., Start: 43.00, End: 44.00\n",
      "Text:  In the library., Start: 44.00, End: 45.00\n",
      "Text:  Bye, Reuben., Start: 45.00, End: 46.00\n",
      "Total time: 215.84 seconds\n",
      "Pipeline initialization time: 2.94 seconds\n",
      "Audio loading time: 0.10 seconds\n",
      "Sample creation time: 0.00 seconds\n",
      "Prediction time: 212.80 seconds\n",
      "Chunk printing time: 0.00 seconds\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Model Performance Summary without Language Information\n",
    "\n",
    "- **Processing Time:**  \n",
    "  The processing of 50 seconds of Hebrew audio took **212 seconds**, which is relatively slow. However, this performance largely depends on the device being used.\n",
    "  \n",
    "- **Unexpected Behavior:**  \n",
    "  The output also includes **translations into English**, which is not required for our task since we only need the Hebrew transcription.\n",
    "  \n",
    "\n"
   ],
   "id": "353871fea5a8c8c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-16T12:27:01.975452Z",
     "start_time": "2024-09-16T12:24:31.789137Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Track the total time for each part\n",
    "start_time = time.time()\n",
    "\n",
    "# Set device to CUDA if available\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Measure pipeline initialization time\n",
    "init_pipe_start = time.time()\n",
    "# Initialize the pipeline for automatic speech recognition\n",
    "pipe = pipeline(\n",
    "  \"automatic-speech-recognition\",\n",
    "  model=\"ivrit-ai/whisper-large-v2-tuned\",\n",
    "  chunk_length_s=30,\n",
    "  device=device,\n",
    ")\n",
    "init_pipe_end = time.time()\n",
    "\n",
    "# Load audio file\n",
    "load_audio_start = time.time()\n",
    "audio_file_path = \"POC_Examples/audio_sample_1.mp3\"\n",
    "audio_array, sampling_rate = librosa.load(audio_file_path, sr=16000)\n",
    "load_audio_end = time.time()\n",
    "\n",
    "# Create a dictionary similar to what the pipeline expects\n",
    "create_sample_start = time.time()\n",
    "sample = {\n",
    "    \"array\": audio_array,\n",
    "    \"sampling_rate\": sampling_rate\n",
    "}\n",
    "create_sample_end = time.time()\n",
    "\n",
    "# Get text prediction with timestamps from the audio file\n",
    "prediction_start = time.time()\n",
    "prediction = pipe(sample, batch_size=8, return_timestamps=True, generate_kwargs={\"language\": \"he\"})[\"chunks\"]\n",
    "\n",
    "prediction_end = time.time()\n",
    "\n",
    "# Print each chunk and the time range\n",
    "print_chunks_start = time.time()\n",
    "for chunk in prediction:\n",
    "    start, end = chunk['timestamp']  # timestamp is a tuple (start, end)\n",
    "    text = chunk['text']\n",
    "    print(f\"Text: {text}, Start: {start:.2f}, End: {end:.2f}\")\n",
    "print_chunks_end = time.time()\n",
    "\n",
    "# Calculate total times\n",
    "total_time = time.time() - start_time\n",
    "pipe_time = init_pipe_end - init_pipe_start\n",
    "load_audio_time = load_audio_end - load_audio_start\n",
    "create_sample_time = create_sample_end - create_sample_start\n",
    "prediction_time = prediction_end - prediction_start\n",
    "print_chunks_time = print_chunks_end - print_chunks_start\n",
    "\n",
    "# Print timing results\n",
    "print(f\"Total time: {total_time:.2f} seconds\")\n",
    "print(f\"Pipeline initialization time: {pipe_time:.2f} seconds\")\n",
    "print(f\"Audio loading time: {load_audio_time:.2f} seconds\")\n",
    "print(f\"Sample creation time: {create_sample_time:.2f} seconds\")\n",
    "print(f\"Prediction time: {prediction_time:.2f} seconds\")\n",
    "print(f\"Chunk printing time: {print_chunks_time:.2f} seconds\")\n"
   ],
   "id": "10031cc6085248da",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f554c00444214e78b151a457a5788722"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: רובן, תחרות אכילת לפות, אתה נגד ערן לוי, מי לוקח?, Start: 0.00, End: 6.00\n",
      "Text:  אה, חוזרים שתרענו אותי על כדורגל, אתם מדברים איתי על לפות עכשיו. דווקא במקרה הזה אני לא אוהב לפות, אבל אם מצא, אז כבר שיהנו. אבל אני לא, עדיף שאני לא נהיה לשאלה הזאת, אמרתי לכם, דברו איתי על כדורגל, לא מעבר לזה., Start: 6.00, End: 18.00\n",
      "Text:  אוקיי, שאלה לגבי כדורגל, למה לכדורגלנים אומרים שאין ידע כללי?, Start: 18.00, End: 23.00\n",
      "Text:  לא יודע, אולי זה סטיגמה, שחושבים שהם אולי טיפשים או משהו כזה?, Start: 23.00, End: 27.88\n",
      "Text:  אמרתי לך, זה..., Start: 27.88, End: 29.04\n",
      "Text:  איך הידע כללי שלך?, Start: 29.04, End: 29.96\n",
      "Text:  בסדר גמור., Start: 30.28, End: 30.96\n",
      "Text:  נגיד, מה היה מקצוע של יוחנן הסנדלר?, Start: 31.08, End: 33.48\n",
      "Text:  לא... דבר איתי משהו בספורט., Start: 33.72, End: 36.28\n",
      "Text:  תודה רובן, אחלה רעיון., Start: 37.48, End: 38.92\n",
      "Text:  כן, רעיון קצר..., Start: 38.92, End: 40.40\n",
      "Text:  נתראה בחתול., Start: 40.40, End: 41.24\n",
      "Text:  כן, איזה חתול., Start: 41.24, End: 42.60\n",
      "Text:  אה, סליחה, בספרייה. ביי רובן., Start: 43.56, End: 45.92\n",
      "Total time: 150.17 seconds\n",
      "Pipeline initialization time: 4.81 seconds\n",
      "Audio loading time: 0.11 seconds\n",
      "Sample creation time: 0.00 seconds\n",
      "Prediction time: 145.25 seconds\n",
      "Chunk printing time: 0.00 seconds\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Model Performance Summary with known language\n",
    "\n",
    "As we can see it still take 150 seconds to process 50 seconds of audio. It better with known language, but still slow.\n",
    "\n"
   ],
   "id": "2515d66db6e6ef3e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Summary\n",
    "\n",
    "- **Model Performance:**\n",
    "    The model take a lot time to process the audio file. It took **212 seconds** to process 50 seconds of audio without language information and **150 seconds** with language information. This is relatively slow and may not be suitable for real-time applications.\n",
    "\n",
    "- **Model Size and Resource Usage:**  \n",
    "  The model itself is **5 GB** in size, and additional libraries also take up considerable space. This results in the model being relatively accurate, but it works slowly and requires significant computational resources.\n",
    "  \n",
    "---\n",
    "\n",
    "Despite the model performing correctly, its slow speed and large size may present challenges in certain scenarios."
   ],
   "id": "2eba4b6bdea09513"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
